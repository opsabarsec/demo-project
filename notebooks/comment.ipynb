{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bafc971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedin_post_text = \"\"\"\n",
    "I’ve now had hundreds of conversations that start the EXACT same way:\n",
    "\n",
    " “We started with a simple RAG pipeline, but then…”\n",
    "\n",
    "But then, came:\n",
    "\n",
    "• Debates about chunking strategies 🤔 \n",
    "• Reranker confusion (“Do I need one? What even is a reranker? Should I use gpt-4o-mini as my reranker?”)\n",
    "• Ad hoc QA tests (“seems better?” 🫠)\n",
    "• Hallucinations despite decent retrieval hits (\"What are we doing wrong?\")\n",
    "• Weeks lost chasing whatever GraphRAG variation is trending on Twitter\n",
    "\n",
    "I’ve seen small teams burn months trying to fix their retrieval when they could’ve been shipping product.\n",
    "\n",
    "I’ve audited a ton of these pipelines (literally >50 in the last few months). Patterns emerge. \n",
    "\n",
    "What surprised me most: almost no one runs rigorous evals on retrieval (the part everything else depends on). \n",
    "So I built zbench, a pipeline for automatic, robust retrieval evaluation.\n",
    "\n",
    "I’m happy to share more about evals, and some of my learnings on what’s actually worked in production (and what didn’t).\n",
    "\n",
    "DM me or reach out at ghita at zeroentropy dot dev!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c684537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Now you can access the variables as if they were set normally\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"OpenAI API Key loaded:\", openai_api_key is not None)\n",
    "\n",
    "\n",
    "client = openai.OpenAI(api_key=openai_api_key)\n",
    "\n",
    "prompt = f\"given this post {linkedin_post_text} write a smart, specific, supportive  comment of a maximum 50 words. End the comment with an open question.\"\n",
    "\n",
    "def generate_comment(prompt):\n",
    "    \"\"\"Generate a comment based on the provided prompt using OpenAI's GPT-4o model.\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=100,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "comment = generate_comment(prompt)\n",
    "\n",
    "print(\"Generated Comment:\")\n",
    "print(comment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
